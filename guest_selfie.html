<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Liveness Selfie (Frontend Only)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root{
      --brand:#0066cc;
      --ok:#1a9b50;
      --warn:#cc8800;
      --bad:#cc3333;
    }
    body { font-family: 'Segoe UI', system-ui, sans-serif; background:#f4f4f4; margin:0; padding:20px; text-align:center; }
    h2 { margin: 8px 0 4px; color:#222; }
    p.tip { margin:0 0 14px; color:#555; font-size:14px; }

    /* Video + overlay stack */
    .cam-wrap{
      width:92%; max-width:360px; margin:0 auto; position:relative;
      border-radius:12px; box-shadow:0 0 8px rgba(0,0,0,.18); overflow:hidden;
      background:#000;
    }
    video{
      width:100%; height:auto; display:block; position:relative; z-index:1;
    }
    /* Mirror ONLY the user-facing preview so it feels natural */
    video.mirror { transform: scaleX(-1); }

    /* Overlay canvas sits ON TOP of the video, same size (not mirrored) */
    canvas.overlay {
      position:absolute; inset:0; width:100%; height:100%;
      display:block; z-index:2; pointer-events:none; background:transparent;
    }

    .status { display:flex; justify-content:center; gap:10px; margin:12px 0 6px; flex-wrap:wrap; }
    .chip { display:inline-flex; align-items:center; gap:8px; background:#fff; border-radius:999px; padding:6px 12px; box-shadow:0 2px 6px rgba(0,0,0,.08); font-size:14px; border:1px solid #eee; }
    .dot { width:10px; height:10px; border-radius:50%; background:#bbb; }
    .dot.ok { background: var(--ok); }
    .dot.wait { background: var(--warn); }
    .dot.bad { background: var(--bad); }

    .instr { margin:10px auto 6px; color:#333; font-weight:600; font-size:16px; max-width:520px; }
    .bar { width:92%; max-width:360px; height:8px; background:#e9eef5; margin:8px auto 12px; border-radius:999px; overflow:hidden; }
    .bar > div { height:100%; width:0%; background:var(--brand); transition:width .2s; }

    button { margin-top:10px; padding:10px 18px; background:var(--brand); color:#fff; border:0; border-radius:10px; font-size:16px; cursor:pointer; }
    button:disabled { opacity:.6; cursor:not-allowed; }

    #loader { display:none; font-size:15px; color:var(--brand); margin:14px 0; }
    .grid { display:grid; grid-template-columns: repeat(auto-fit, minmax(220px, 1fr)); gap:16px; padding:16px 0; }
    .grid-item { position:relative; }
    .grid-item img { width:100%; height:200px; object-fit:cover; border-radius:10px; box-shadow:0 2px 6px rgba(0,0,0,.1); }
    .download-tip { position:absolute; bottom:8px; left:50%; transform:translateX(-50%); background:rgba(0,0,0,.6); color:#fff; padding:4px 8px; font-size:13px; border-radius:5px; display:none; }
    .grid-item:hover .download-tip { display:block; }
    .hidden { display:none !important; }
    .note { font-size:12px; color:#666; margin-top:6px; }
  </style>
</head>
<body>
  <h2>Upload Your Selfie</h2>
  <p class="tip">Hold mobile at eye leve,Tap Start, allow camera once, and look straight.</p>

  <div class="status">
    <div class="chip"><span class="dot" id="dotCenter"></span>Face forward</div>
    <div class="chip"><span class="dot" id="dotLeft"></span>Turn left</div>
    <div class="chip"><span class="dot" id="dotRight"></span>Turn right</div>
  </div>

  <!-- <div class="instr" id="instruction">When ready, look straight at the camera.</div> -->
  <div class="bar"><div id="progress"></div></div>

  <div class="cam-wrap">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="overlay" class="overlay"></canvas>
  </div>

  <canvas id="canvas" class="hidden"></canvas>

  <div style="margin-top:8px;">
    <button id="startBtn">Start</button>
    <button id="captureBtn" disabled>Search my photos</button>
  </div>
  <div class="note">You’ll only be asked for camera permission when you press Start.</div>

  <div id="loader">Processing selfie...</div>
  <div id="resultArea" class="grid"></div>

  <!-- TensorFlow.js + BlazeFace -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.15.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const octx = overlay.getContext('2d');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    const instructionEl = document.getElementById('instruction');
    const progressEl = document.getElementById('progress');
    const startBtn = document.getElementById('startBtn');
    const captureBtn = document.getElementById('captureBtn');
    const loader = document.getElementById('loader');
    const resultArea = document.getElementById('resultArea');

    const dotCenter = document.getElementById('dotCenter');
    const dotLeft = document.getElementById('dotLeft');
    const dotRight = document.getElementById('dotRight');

    // Camera/model state
    let mediaStream = null;
    let model = null;
    let isMirrored = false;

    // Liveness state
    let running = false;
    let gotCenter = false, gotLeft = false, gotRight = false;
    let holdFrames = 16;     // ~0.5s at ~30fps
    let centerCount = 0, leftCount = 0, rightCount = 0;

    // Yaw proxy thresholds
    const CENTER_T = 0.05;
    const SIDE_T = 0.10;

    function currentTargetText() {
      if (!gotCenter) return "Look straight at the camera and hold still…";
      if (!gotLeft) return "Slowly turn your head to the LEFT and hold…";
      if (!gotRight) return "Now turn your head to the RIGHT and hold…";
      return "Great! Liveness passed — you can now search your photos.";
    }

    function mark(el, state) {
      el.classList.remove('ok','wait','bad');
      if (state === 'ok') el.classList.add('ok');
      else if (state === 'wait') el.classList.add('wait');
      else if (state === 'bad') el.classList.add('bad');
    }

    async function initCameraOnce() {
      if (mediaStream && mediaStream.active) {
        video.srcObject = mediaStream;
      } else {
        mediaStream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: false });
        video.srcObject = mediaStream;
      }

      // Mirror preview for front cam (video only)
      const track = mediaStream.getVideoTracks()[0];
      const settings = track.getSettings ? track.getSettings() : {};
      isMirrored = (settings.facingMode === 'user') || true; // default to true
      if (isMirrored) {
        video.classList.add('mirror');
      }

      await new Promise(res => video.onloadedmetadata = res);
      resizeOverlay();
      window.addEventListener('resize', resizeOverlay, { passive:true });
    }

    function resizeOverlay() {
      // Match the overlay canvas to the DISPLAYED size of the video element
      const rect = video.getBoundingClientRect();
      const dpr = window.devicePixelRatio || 1;
      overlay.width = Math.max(1, Math.round(rect.width * dpr));
      overlay.height = Math.max(1, Math.round(rect.height * dpr));
      overlay.style.width = rect.width + 'px';
      overlay.style.height = rect.height + 'px';
      octx.setTransform(dpr, 0, 0, dpr, 0, 0);
    }

    function estimateYawOffset(pred) {
      const lm = pred.landmarks;
      if (!lm || lm.length < 3) return null;
      const rightEye = lm[0];
      const leftEye  = lm[1];
      const nose     = lm[2];
      const eyesMidX = (rightEye[0] + leftEye[0]) / 2;
      const faceWidth = (pred.bottomRight[0] - pred.topLeft[0]) || 1;
      let offset = (nose[0] - eyesMidX) / faceWidth; // >0 = turned toward image RIGHT
      if (isMirrored) offset = -offset;              // correct for mirrored preview
      return offset;
    }

    function drawOverlay(pred, phase, yaw) {
      // Clear
      octx.clearRect(0, 0, overlay.width, overlay.height);
      if (!pred) return;

      // Map MODEL coords (video intrinsic px) -> DISPLAY coords (CSS px)
      const vw = video.videoWidth || 1;
      const vh = video.videoHeight || 1;
      const rect = video.getBoundingClientRect();
      const sx = rect.width / vw;
      const sy = rect.height / vh;

      // Coordinates from model space
      let x = pred.topLeft[0] * sx;
      const y = pred.topLeft[1] * sy;
      const w = (pred.bottomRight[0] - pred.topLeft[0]) * sx;
      const h = (pred.bottomRight[1] - pred.topLeft[1]) * sy;

      // If preview is mirrored (video only), flip X so overlay aligns
      if (isMirrored) {
        x = rect.width - (x + w);
      }

      // Thinner blue box
      octx.lineWidth = 2;
      octx.strokeStyle = '#00d2ff';
      octx.strokeRect(x, y, w, h);

      // Progress bar at top: reflect current hold progress
      const prog = (!gotCenter ? centerCount/holdFrames :
                   !gotLeft ? leftCount/holdFrames :
                   !gotRight ? rightCount/holdFrames : 1);
      progressEl.style.width = Math.min(100, Math.max(0, prog * 100)) + '%';

      // Small progress arc near box (optional visual)
      octx.beginPath();
      octx.strokeStyle = '#0066cc';
      octx.lineWidth = 3;
      octx.arc(x + 16, y + 16, 10, -Math.PI/2, -Math.PI/2 + Math.min(1, Math.max(0, prog)) * 2*Math.PI);
      octx.stroke();

      // Big < > glyphs OUTSIDE the box in the correct places
      octx.font = `bold ${Math.max(30, h*0.3)}px Arial`;
      octx.fillStyle = '#ffb200';
      octx.textAlign = 'center';
      octx.textBaseline = 'middle';
      const arrowOffset = Math.max(30, w * 0.25);

      if (!gotLeft && phase === 'left') {
        // Show a '<' to the LEFT of the visible box
        octx.fillText('<', x - arrowOffset, y + h/2);
      } else if (!gotRight && phase === 'right') {
        // Show a '>' to the RIGHT of the visible box
        octx.fillText('>', x + w + arrowOffset, y + h/2);
      }

      // (Optional) yaw debug
      // octx.fillStyle = 'rgba(0,0,0,.6)';
      // octx.fillRect(x, y + h + 8, 80, 20);
      // octx.fillStyle = '#fff';
      // octx.font = '12px system-ui';
      // octx.fillText('yaw: ' + (yaw!==null? yaw.toFixed(2):'--'), x + 6, y + h + 22);
    }

    async function livenessLoop() {
      if (!running) return;
      const preds = await model.estimateFaces(video, false);
      let best = null, yaw = null;

      if (preds && preds.length > 0) {
        // choose largest face
        let bestArea = 0;
        for (const p of preds) {
          const w = p.bottomRight[0] - p.topLeft[0];
          const h = p.bottomRight[1] - p.topLeft[1];
          const a = Math.max(0, w) * Math.max(0, h);
          if (a > bestArea) { bestArea = a; best = p; }
        }

        yaw = estimateYawOffset(best);
        if (yaw !== null) {
          if (!gotCenter) {
            if (Math.abs(yaw) <= CENTER_T) { centerCount++; mark(dotCenter,'wait'); }
            else { centerCount = 0; mark(dotCenter,'bad'); }
            if (centerCount >= holdFrames) { gotCenter = true; mark(dotCenter,'ok'); }
          } else if (!gotLeft) {
            if (yaw <= -SIDE_T) { leftCount++; mark(dotLeft,'wait'); }
            else { leftCount = 0; mark(dotLeft,'bad'); }
            if (leftCount >= holdFrames) { gotLeft = true; mark(dotLeft,'ok'); }
          } else if (!gotRight) {
            if (yaw >= SIDE_T) { rightCount++; mark(dotRight,'wait'); }
            else { rightCount = 0; mark(dotRight,'bad'); }
            if (rightCount >= holdFrames) { gotRight = true; mark(dotRight,'ok'); }
          }
        }
      }

      // Phase for guidance
      const phase = !gotCenter ? 'center' : !gotLeft ? 'left' : !gotRight ? 'right' : 'done';
      drawOverlay(best, phase, yaw);

      instructionEl.textContent = currentTargetText();

      if (gotCenter && gotLeft && gotRight) {
        progressEl.style.width = '100%';
        captureBtn.disabled = false;
        running = false;
        return;
      }
      requestAnimationFrame(livenessLoop);
    }

    async function startLiveness() {
      // Reset
      gotCenter = gotLeft = gotRight = false;
      centerCount = leftCount = rightCount = 0;
      mark(dotCenter,null); mark(dotLeft,null); mark(dotRight,null);
      progressEl.style.width = '0%';
      instructionEl.textContent = "Preparing camera and face tracker…";
      captureBtn.disabled = true;
      startBtn.disabled = true;

      try {
        await initCameraOnce();
      } catch (e) {
        startBtn.disabled = false;
        alert("Camera access is required for liveness. Please allow permission and try again.");
        return;
      }

      if (!model) {
        instructionEl.textContent = "Loading face model…";
        model = await blazeface.load();
      }

      instructionEl.textContent = currentTargetText();
      running = true;
      requestAnimationFrame(livenessLoop);
    }

    async function captureAndUpload() {
      if (!(gotCenter && gotLeft && gotRight)) {
        alert("Please finish the liveness steps first.");
        return;
      }

      // Capture current frame (upload un-mirrored pixels from raw video)
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      loader.style.display = "block";
      resultArea.innerHTML = "";

      canvas.toBlob(async (blob) => {
        const formData = new FormData();
        formData.append("file", blob, "selfie.jpg");

        try {
          const response = await fetch("https://my-event-pictures-backend.onrender.com/upload-selfie", {
            method: "POST",
            body: formData
          });
          const result = await response.json();
          loader.style.display = "none";

          if (result.matched_images && result.matched_images.length > 0) {
            result.matched_images.forEach(imgName => {
              const link = document.createElement("a");
              link.href = `https://my-event-pictures-backend.onrender.com/event_photos/${imgName}`;
              link.download = imgName;
              link.target = "_blank";

              const wrapper = document.createElement("div");
              wrapper.className = "grid-item";

              const img = document.createElement("img");
              img.src = link.href;

              const tip = document.createElement("div");
              tip.className = "download-tip";
              tip.innerText = "Download Image";

              wrapper.appendChild(img);
              wrapper.appendChild(tip);
              link.appendChild(wrapper);
              resultArea.appendChild(link);
            });
          } else {
            alert(result.message || "❌ No matches found.");
          }
        } catch (err) {
          loader.style.display = "none";
          alert("❌ Upload failed.");
          console.error(err);
        }
      }, 'image/jpeg', 0.95);
    }

    // Buttons
    startBtn.addEventListener('click', startLiveness);
    captureBtn.addEventListener('click', captureAndUpload);

    // No auto-permission on load — we only ask inside startLiveness().
  </script>
</body>
</html>


